https://deepmind.com/blog/article/alphago-zero-starting-scratch

In 2016, Alpha Go, a neural net trained to play the ancient board game Go, defeated Lee Sedol, one of the greatest Go players in the world. At the time, this [made headlines](https://www.nytimes.com/2016/03/10/world/asia/google-alphago-lee-se-dol.html), but, interestingly, DeepMind, the lab behind the effort (now a subsidiary of Google), has continued to refine the program.

According to [this report](https://deepmind.com/blog/article/alphago-zero-starting-scratch), published a year later by DeepMind, the program's newer iteration, Alpha Go Zero, not only uses less energy and learns more efficiently (if you look at the graph, the decrease in energy consumption from the neural net is shocking, and hopefully a sign that similar improvements are possible with other neural nets, given how energy-intensive--and therefore carbon-intensive--their training is), it also has generated "new knowledge" and "creative new moves", after undergoing the equivalent of thousands of human-years of learning how to play Go.

Given what we learned last week, this news seems at once trivial and pathbreaking, depending on how you look at it. On the one hand, it's astonishing how much progress was made even after all the headlines stopped in 2016; one wonders how, if at all, this sort of neural net can be applied to other problems, such as the energy consumption of neural nets. (It's not clear from this article alone if the increase in efficiency reported by DeepMind is a commonplace occurrence at this point, but one assumes not.)
On the one hand, games are super unnecessary. On the other, as the philosopher Bernard Suits eloquently argued in his treatise *[The Grasshopper: Games, Life and Utopia](https://broadviewpress.com/product/the-grasshopper-third-edition/#tab-description)*, games are, in some sense, the point of life--after all, games are a wellspring of meaning and purpose in a world where meaning and purpose are sometimes in short supply.

Similarly, as the journalist Oliver Roeder argues, in *[Seven Games: A Human History](https://www.nytimes.com/2022/01/25/books/review/seven-games-oliver-roeder.html)*, games play a pivotal role in human culture, as evidence of games exists going back 5000 years. So, perhaps teaching a computer to play a game is a worthwhile end in and of itself. At the same time, when AIs can play games--and better than humans--what's the point of playing anymore? Or is winning besides the point? (I will certainly never solve a Rubik's Cube as fast as the fastest robot, but it was still incredibly meaningful to learn to solve the puzzle.)

This is all to say that I can't give a definitive answer to the question of whether this use of a neural net is necessary, or useful. It seems marginally ethical--in that it's not doing harm, beyond the normal harm that neural nets do, with their massive consumption of electricity. It's not training robots to harm humans, but it's also not really helping anyone either. (Certainly, for the people who designed the program, I imagine this was tremendously fun.)
